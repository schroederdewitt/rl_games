params:  
  algo:
    name: a2c_discrete

  model:
    name: discrete_a2c

  network:
    name: actor_critic
    separate: True
    value_shape: 2
    space: 
      discrete:
      
    mlp:
      units: [64, 64]
      activation: relu
      initializer:
        name: variance_scaling_initializer
        scale: 2 
      regularizer:
        name: 'None'
  load_checkpoint: False
  config:
      reward_shaper:
        scale_value: 0.1
      normalize_advantage: True
      gamma: 0.99
      tau: 0.9

      learning_rate: 5e-4
      name: test
      score_to_win: 200

      grad_norm: 0.5
      entropy_coef: 0.001
      truncate_grads: True
      #env_name:  LunarLander-v2
      env_name: MountainCar-v0
      ppo: true
      e_clip: 0.2
      clip_value: True
      num_actors: 16
      steps_num: 128
      minibatch_size: 1024
      mini_epochs: 2
      critic_coef: 1
      lr_schedule:  None
      lr_threshold: 0.008

      normalize_input: True
      seq_len: 8
      bounds_loss_coef: 0

      rnd_config:
        scale_value: 256.0
        episodic: True
        episode_length: 32
        gamma: 0.99
        mini_epochs: 2
        minibatch_size: 1024
        lr: 5e-4
        network:
          name: rnd_curiosity
          mlp:
            rnd:
              units: [64,64,16]
            net:
              units: [32,16]
            activation: elu
            initializer:
                name: variance_scaling_initializer
                scale: 2
            regularizer:
              name:  'None' 
